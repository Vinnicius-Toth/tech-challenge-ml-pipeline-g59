# ğŸš€ tech-challenge-ml-pipeline-g59

Projeto Tech Challenge - Fase 3 - Engenharia de Machine Learning  
Pipeline de PrediÃ§Ã£o de Valores do Bolsa FamÃ­lia

---

## ğŸ“š VisÃ£o Geral

Este projeto implementa um pipeline completo de Machine Learning para prever os valores mensais do programa Bolsa FamÃ­lia por municÃ­pio, utilizando dados histÃ³ricos, engenharia de features, treinamento de modelo XGBoost e exportaÃ§Ã£o de previsÃµes e artefatos para o MinIO. Os resultados podem ser integrados ao Power BI para visualizaÃ§Ã£o.

---

## ğŸ—‚ï¸ Estrutura do Projeto

```
tech-challenge-ml-pipeline-g59/
â”œâ”€â”€ pipeline_medallion_datalake/   # Pipeline ETL Medallion (Stage, Raw, Silver, Gold)
â”‚   â”œâ”€â”€ medallion_layers/
â”‚   â”‚   â”œâ”€â”€ stage/
â”‚   â”‚   â”œâ”€â”€ raw/
â”‚   â”‚   â”œâ”€â”€ silver/
â”‚   â”‚   â””â”€â”€ gold/
â”‚   â”œâ”€â”€ enums.py
â”‚   â”œâ”€â”€ logger.py
â”‚   â”œâ”€â”€ main.py
â”‚   â”œâ”€â”€ minio_client.py
â”‚   â””â”€â”€ utils.py
â”œâ”€â”€ pipeline_predict/              # Pipeline de prediÃ§Ã£o ML
â”‚   â”œâ”€â”€ ingest.py
â”‚   â”œâ”€â”€ features.py
â”‚   â”œâ”€â”€ train.py
â”‚   â”œâ”€â”€ forecast.py
â”‚   â”œâ”€â”€ export.py
â”‚   â”œâ”€â”€ minio_client.py
â”‚   â”œâ”€â”€ logger.py
â”‚   â””â”€â”€ main.py
â”œâ”€â”€ data/                          # Dados auxiliares e arquivos consolidados
â”‚   â”œâ”€â”€ Coordenadas_Municipios_IBGE.json   # Coordenadas geogrÃ¡ficas dos municÃ­pios
â”‚   â”œâ”€â”€ Coordenadas_UF_IBGE.json           # Coordenadas geogrÃ¡ficas dos estados
â”‚   â””â”€â”€ *.parquet                          # Arquivos Parquet consolidados para anÃ¡lise local
â”œâ”€â”€ artefatos/                     # Arquivo PowerBI
â””â”€â”€ README.md
```

---

## ğŸ”— Pipeline de Dados Datalake

### pipeline_medallion_datalake

O pipeline `pipeline_medallion_datalake` Ã© responsÃ¡vel por toda a ingestÃ£o, limpeza, transformaÃ§Ã£o e organizaÃ§Ã£o dos dados em mÃºltiplas camadas no MinIO, seguindo o padrÃ£o Medallion Architecture:

- **Stage:** Recebe os dados brutos, exatamente como foram extraÃ­dos da fonte do [Bolsa Familia](https://portaldatransparencia.gov.br/download-de-dados/bolsa-familia-saques).
- **Raw:** Realiza pequenas limpezas e padronizaÃ§Ãµes, mantendo a granularidade original, convertendo em parquet.
- **Silver:** Aplica transformaÃ§Ãµes, normalizaÃ§Ãµes e enriquecimentos, tornando os dados prontos para anÃ¡lise.
- **Gold:** Dados agregados e otimizados para consumo analÃ­tico e modelagem, particionados por ano/mÃªs.

O processo Ã© orquestrado pelo script [`main.py`](pipeline_medallion_datalake/main.py), que executa cada etapa sequencialmente e salva os arquivos Parquet em buckets e pastas especÃ­ficas do MinIO.

---

## ğŸ”— Pipeline de PrediÃ§Ã£o

### pipeline_predict

O pipeline `pipeline_predict` Ã© responsÃ¡vel por todo o processo de previsÃ£o utilizando Machine Learning:

1. **IngestÃ£o dos Dados Gold:**  
   O script [`ingest.py`](pipeline_predict/ingest.py) lÃª todos os arquivos Parquet da camada gold do MinIO e concatena em um Ãºnico DataFrame para modelagem.

2. **Engenharia de Features:**  
   O script [`features.py`](pipeline_predict/features.py) cria variÃ¡veis histÃ³ricas (lags, mÃ©dias mÃ³veis, trimestre, etc.) e codifica variÃ¡veis categÃ³ricas, salvando o encoder no MinIO.

3. **Treinamento do Modelo:**  
   O script [`train.py`](pipeline_predict/train.py) treina um modelo XGBoost para prever o valor da parcela do Bolsa FamÃ­lia, salvando o modelo treinado no bucket de artefatos.

4. **GeraÃ§Ã£o de PrevisÃµes:**  
   O script [`forecast.py`](pipeline_predict/forecast.py) utiliza o modelo treinado para gerar previsÃµes mÃªs a mÃªs para cada municÃ­pio, considerando os Ãºltimos valores histÃ³ricos.

5. **ExportaÃ§Ã£o de Resultados:**  
   O script [`export.py`](pipeline_predict/export.py) salva as previsÃµes e artefatos (modelo, encoder) no MinIO, organizando por ano de previsÃ£o.

6. **IntegraÃ§Ã£o com Power BI:**  
   Os arquivos Parquet de previsÃµes podem ser baixados do MinIO e utilizados diretamente no Power BI para anÃ¡lise e visualizaÃ§Ã£o.

---

## ğŸ³ Como subir o MinIO com Docker

Para executar o MinIO localmente utilizando Docker, siga os passos abaixo:

```sh
docker run -d -p 9000:9000 -p 9001:9001 \
  --name minio \
  -e "MINIO_ROOT_USER=admin" \
  -e "MINIO_ROOT_PASSWORD=admin123" \
  minio/minio server /data --console-address ":9001"
```

- O MinIO estarÃ¡ disponÃ­vel em: [http://localhost:9000](http://localhost:9000)
- O painel de administraÃ§Ã£o estarÃ¡ em: [http://localhost:9001](http://localhost:9001)
- UsuÃ¡rio: `admin`
- Senha: `admin123`

> **ObservaÃ§Ã£o:** NÃ£o Ã© necessÃ¡rio criar os buckets manualmente, pois as pipelines jÃ¡ realizam essa tarefa automaticamente.

---

## âš™ï¸ Arquitetura

> ![Exemplo de arquitetura](docs/arquitetura_pipeline_bolsa_familia.png)  
> *(Adicione um desenho da arquitetura do seu pipeline aqui, se desejar)*

---

## ğŸ” Como Executar

### 1. Requisitos

- Python 3.10+
- MinIO rodando localmente (`localhost:9000`)
- Bibliotecas: pandas, xgboost, scikit-learn, joblib, minio, pyarrow

Instale as dependÃªncias:

```sh
pip install -r requirements.txt
```

### 2. Execute o Pipeline Medallion

```sh
cd pipeline_medallion_datalake
python main.py
```

### 3. Execute o Pipeline de PrediÃ§Ã£o

```sh
cd pipeline_predict
python main.py
```

### 4. Visualize no Power BI

- Baixe os arquivos Parquet de previsÃµes do MinIO para uma pasta local.
- No Power BI: Obter Dados â†’ Pasta â†’ Selecione a pasta com os arquivos.

---

## ğŸ“ VariÃ¡veis e ConfiguraÃ§Ãµes

- Buckets MinIO: `datalake` (dados), `artefatos` (modelos/encoders)
- Dados auxiliares: [`data/Coordenadas_UF_IBGE.json`](data/Coordenadas_UF_IBGE.json)

---

## ğŸ”„ CI/CD

Este projeto pode ser facilmente integrado a pipelines de CI/CD e orquestradores como Airflow ou Task Scheduler para automaÃ§Ã£o.

---

## ğŸ§° Tecnologias Utilizadas

- Python 3.10+
- Pandas
- XGBoost
- Scikit-learn
- MinIO
- Power BI

---

## ğŸ‘¨â€ğŸ’» Desenvolvedores

- Vinnicius Toth â€“ Engenheiro de Dados e Machine Learning  
- G59 Team â€“ FIAP Tech Challenge 3

---